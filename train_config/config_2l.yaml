###########################################################
#                   DATA SETTING                          #
###########################################################
data:
  path: "./out_features/"
  subset:
    train: "arabic+libri_1000hours_data"
    valid: "arabic+libri_eval"
    test:  "arabic+libri_test"

###########################################################
#                   MODEL SETTING                         #
###########################################################
model_params:
  n_filters: 64
  strides: [8,5,4,2]
  dimension: 768
  semantic_dimension: 1280
  bidirectional: true
  dilation_base: 2
  residual_kernel_size: 3
  n_residual_layers: 1
  lstm_layers: 2
  activation: "ELU"
  sample_rate: 16000
  codebook_size: 1024
  n_q: 8

###########################################################
#                 METRIC LOSS SETTING                     #
###########################################################
loss_params:
  lambda_time_reconstruct_loss: 500
  lambda_freq_reconstruct_loss: [45, 1, 1, 1]
  lambda_commit_loss: 10
  lambda_repr_distillation_loss: 120
  distill_loss_type: "d_axis"

###########################################################
#                  Mel-spectrogram SETTING                #
###########################################################
mel_params:
  n_fft: 1024
  num_mels: 80
  hop_size: 240
  win_size: 1024
  fmin: 0
  fmax_for_loss: null

###########################################################
#                  DATA LOADER SETTING                    #
###########################################################
batch_size: 32              # Batch size.
batch_length: 96            # Length of each audio in batch (training w/o adv).
pin_memory: false            # Whether to pin memory in Pytorch DataLoader.
num_workers: 4              # Number of workers in Pytorch DataLoader.
num_lang_class: 2
language_list: ["arabic","english"]
###########################################################
#             OPTIMIZER & SCHEDULER SETTING               #
###########################################################
model_optimizer_type: Adam
disc_optimizer_type: Adam
fc_optimizer_type: Adam
model_optimizer_params:
  lr: 1.0e-4
  betas: [0.5, 0.9]
  weight_decay: 0.0

fc_optimizer_params:
  lr: 1.0e-4
  betas: [0.5, 0.9]
  weight_decay: 0.0

disc_optimizer_params:
  lr: 1.0e-4
  betas: [0.5, 0.9]
  weight_decay: 0.0
model_scheduler_type: StepLR
model_scheduler_params:
  step_size: 200000      # Model's scheduler step size.
  gamma: 1.0

fc_scheduler_type: StepLR
fc_scheduler_params:
  step_size: 200000      # Model's scheduler step size.
  gamma: 1.0
disc_scheduler_type: StepLR
disc_scheduler_params:
  step_size: 200000      # Model's scheduler step size.
  gamma: 1.0
grad_norm: -1

###########################################################
#                    INTERVAL SETTING                     #
###########################################################
train_max_steps: 200000           # Number of training steps. (w/o adv)
save_interval_steps: 20000         # Interval steps to save checkpoint.
eval_interval_steps: 2000         # Interval steps to evaluate the network.
log_interval_steps: 100            # Interval steps to record the training log.
